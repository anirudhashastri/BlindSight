{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pyttsx3\n",
    "import ollama\n",
    "import speech_recognition as sr\n",
    "from fuzzywuzzy import process\n",
    "import pyttsx3\n",
    "from docx import Document\n",
    "import ollama\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "# Function to speak text\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Listen to voice commands\n",
    "def listen(mic_index=None):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index) if mic_index is not None else sr.Microphone()\n",
    "    \n",
    "    with mic as source:\n",
    "        print(\"Listening for command...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "        \n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {command}\")\n",
    "            return command.lower()\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I didn't catch that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            speak(\"Sorry, there was a network error.\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Intent recognition using LLM\n",
    "def recognize_intent_with_llm(command):\n",
    "    prompt = (\n",
    "        f\"User command: \\\"{command}\\\"\\n\"\n",
    "        \"Identify the intent of the command and respond with one of these labels:\\n\"\n",
    "        \"add_text, delete_line, read_document, read_line, next_line, previous_line, edit_line, exit.\\n\"\n",
    "        \"Respond only with the intent label and nothing else.\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    intent = \"\"\n",
    "    for chunk in stream:\n",
    "        intent += chunk['message']['content']\n",
    "    \n",
    "    return intent.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract line number using LLM\n",
    "def get_line_number_with_llm(command):\n",
    "    prompt = (\n",
    "        f\"User input: \\\"{command}\\\"\\n\"\n",
    "        \"Identify and respond with only the numeric line number mentioned in the input. \"\n",
    "        \"For example, if the input is 'read line three,' respond with '3'. No extra text, just the number.\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    line_number = \"\"\n",
    "    for chunk in stream:\n",
    "        line_number += chunk['message']['content']\n",
    "    \n",
    "    return line_number.strip()\n",
    "\n",
    "\n",
    "# Open and initialize document\n",
    "def open_document(filename):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        return Document(filename)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        with open(filename, \"r+\") as file:\n",
    "            return file.read().splitlines()  # Treat each line as an entry in a list\n",
    "\n",
    "\n",
    "# Save changes to the document\n",
    "def save_document(content, filename):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        content.save(filename)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(\"\\n\".join(content))  # Save content list back to file\n",
    "\n",
    "\n",
    "# Add text to the document\n",
    "def add_text(content, filename, new_text):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        content.add_paragraph(new_text)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        content.append(new_text)\n",
    "    speak(\"Text added successfully.\")\n",
    "\n",
    "# Delete text by line number\n",
    "def delete_line(content, line_num, filename):\n",
    "    try:\n",
    "        if filename.endswith(\".docx\"):\n",
    "            paragraph = content.paragraphs[line_num]\n",
    "            paragraph.clear()\n",
    "        elif filename.endswith(\".txt\"):\n",
    "            content.pop(line_num)\n",
    "        speak(\"Line deleted successfully.\")\n",
    "    except IndexError:\n",
    "        speak(\"Invalid line number.\")\n",
    "\n",
    "# Use LLM to edit a specific line\n",
    "def edit_line_with_llm(original_line, edit_instruction):\n",
    "    prompt = (\n",
    "        f\"Original line: \\\"{original_line}\\\"\\n\"\n",
    "        f\"Edit request: {edit_instruction}\\n\"\n",
    "        \"Provide only the updated line with no extra text:\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    edited_line = \"\"\n",
    "    for chunk in stream:\n",
    "        edited_line += chunk['message']['content']\n",
    "\n",
    "    return edited_line.strip()\n",
    "\n",
    "\n",
    "# Read and navigate through the document\n",
    "def read_document(content, filename, line_num=None):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        text = content.paragraphs[line_num].text if line_num is not None else \"\\n\".join([p.text for p in content.paragraphs])\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        text = content[line_num] if line_num is not None else \"\\n\".join(content)\n",
    "    \n",
    "    speak(text)\n",
    "\n",
    "\n",
    "\n",
    "def edit_document(mic_index, file_path):\n",
    "    # Hardcoded file path for testing\n",
    "    filename = file_path\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        speak(\"File not found. Please try again.\")\n",
    "        return\n",
    "\n",
    "    # Open the document\n",
    "    content = open_document(filename)\n",
    "    current_line = 0\n",
    "\n",
    "    speak(\"File opened successfully. You can say commands like add text, delete line, edit line, or read document.\")\n",
    "    \n",
    "    while True:\n",
    "        command = listen(mic_index)\n",
    "        intent = recognize_intent_with_llm(command)\n",
    "        \n",
    "        if intent == \"exit\":\n",
    "            save_document(content, filename)\n",
    "            speak(\"Changes saved. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        elif intent == \"add_text\":\n",
    "            speak(\"What text would you like to add?\")\n",
    "            new_text = listen(mic_index)\n",
    "            add_text(content, filename, new_text)\n",
    "\n",
    "        elif intent == \"delete_line\":\n",
    "            speak(\"Which line number would you like to delete?\")\n",
    "            try:\n",
    "                line_num = int(get_line_number_with_llm(listen(mic_index)))\n",
    "                delete_line(content, line_num - 1, filename)\n",
    "            except ValueError:\n",
    "                speak(\"Invalid line number.\")\n",
    "\n",
    "        elif intent == \"read_document\":\n",
    "            read_document(content, filename)\n",
    "\n",
    "        elif intent == \"read_line\":\n",
    "            speak(\"Which line number would you like to hear?\")\n",
    "            try:\n",
    "                line_command = listen(mic_index)\n",
    "                line_num = int(get_line_number_with_llm(line_command))\n",
    "                read_document(content, filename, line_num - 1)\n",
    "            except ValueError:\n",
    "                speak(\"Invalid line number.\")\n",
    "        \n",
    "        elif intent == \"next_line\":\n",
    "            current_line += 1\n",
    "            read_document(content, filename, current_line)\n",
    "\n",
    "        elif intent == \"previous_line\":\n",
    "            current_line = max(0, current_line - 1)\n",
    "            read_document(content, filename, current_line)\n",
    "        \n",
    "        elif intent == \"edit_line\":\n",
    "            speak(\"Which line number would you like to edit?\")\n",
    "            try:\n",
    "                line_command = listen(mic_index)\n",
    "                line_num = int(get_line_number_with_llm(line_command)) - 1\n",
    "                \n",
    "                original_line = content.paragraphs[line_num].text if filename.endswith(\".docx\") else content[line_num]\n",
    "                \n",
    "                speak(\"What changes would you like to make?\")\n",
    "                edit_instruction = listen(mic_index)\n",
    "                \n",
    "                # Get edited line from LLM\n",
    "                edited_line = edit_line_with_llm(original_line, edit_instruction)\n",
    "                \n",
    "                # Update the document with the edited line\n",
    "                if filename.endswith(\".docx\"):\n",
    "                    content.paragraphs[line_num].text = edited_line\n",
    "                elif filename.endswith(\".txt\"):\n",
    "                    content[line_num] = edited_line\n",
    "                \n",
    "                speak(\"Line edited successfully.\")\n",
    "            except (ValueError, IndexError):\n",
    "                speak(\"Invalid line number or edit command.\")\n",
    "        \n",
    "        else:\n",
    "            speak(\"Sorry, I didn't understand that command. Please try again.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available microphones:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Headset Microphone (Oculus Virt\n",
      "2: Microphone (G435 Wireless Gamin\n",
      "3: Microphone (Realtek USB Audio)\n",
      "4: Microphone (3- USB PnP Audio De\n",
      "5: Microphone (Steam Streaming Mic\n",
      "6: Headset Microphone (2- Big bro)\n",
      "7: Microsoft Sound Mapper - Output\n",
      "8: Speakers (2- Big bro)\n",
      "9: Realtek Digital Output (Realtek\n",
      "10: Headphones (Realtek USB Audio)\n",
      "11: ASUS VG32V (NVIDIA High Definit\n",
      "12: Headphones (Oculus Virtual Audi\n",
      "13: Headset Earphone (G435 Wireless\n",
      "14: Speakers (Steam Streaming Speak\n",
      "15: Speakers (Steam Streaming Micro\n",
      "16: U32J59x (NVIDIA High Definition\n",
      "17: Primary Sound Capture Driver\n",
      "18: Headset Microphone (Oculus Virtual Audio Device)\n",
      "19: Microphone (G435 Wireless Gaming Headset)\n",
      "20: Microphone (Realtek USB Audio)\n",
      "21: Microphone (3- USB PnP Audio Device)\n",
      "22: Microphone (Steam Streaming Microphone)\n",
      "23: Headset Microphone (2- Big bro)\n",
      "24: Primary Sound Driver\n",
      "25: Speakers (2- Big bro)\n",
      "26: Headphones (Realtek USB Audio)\n",
      "27: ASUS VG32V (NVIDIA High Definition Audio)\n",
      "28: Headphones (Oculus Virtual Audio Device)\n",
      "29: Realtek Digital Output (Realtek USB Audio)\n",
      "30: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "31: Speakers (Steam Streaming Speakers)\n",
      "32: Speakers (Steam Streaming Microphone)\n",
      "33: U32J59x (NVIDIA High Definition Audio)\n",
      "34: Headphones (Realtek USB Audio)\n",
      "35: ASUS VG32V (NVIDIA High Definition Audio)\n",
      "36: Headphones (Oculus Virtual Audio Device)\n",
      "37: Speakers (2- Big bro)\n",
      "38: Realtek Digital Output (Realtek USB Audio)\n",
      "39: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "40: Speakers (Steam Streaming Speakers)\n",
      "41: Speakers (Steam Streaming Microphone)\n",
      "42: U32J59x (NVIDIA High Definition Audio)\n",
      "43: Microphone (G435 Wireless Gaming Headset)\n",
      "44: Headset Microphone (2- Big bro)\n",
      "45: Headset Microphone (Oculus Virtual Audio Device)\n",
      "46: Microphone (Realtek USB Audio)\n",
      "47: Microphone (3- USB PnP Audio Device)\n",
      "48: Microphone (Steam Streaming Microphone)\n",
      "49: Microphone (USB PnP Audio Device)\n",
      "50: Output 1 (OCULUSVAD Wave Speaker Headphone)\n",
      "51: Output 2 (OCULUSVAD Wave Speaker Headphone)\n",
      "52: Input (OCULUSVAD Wave Speaker Headphone)\n",
      "53: Headset Microphone (OCULUSVAD Wave Microphone Headphone)\n",
      "54: Microphone (G435 Wireless Gaming Headset)\n",
      "55: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "56: Output (NVIDIA High Definition Audio)\n",
      "57: Output ()\n",
      "58: Line In (Realtek USB Audio)\n",
      "59: Microphone (Realtek USB Audio)\n",
      "60: Stereo Mix (Realtek USB Audio)\n",
      "61: Headphones (Realtek USB Audio)\n",
      "62: Speakers (Realtek USB Audio)\n",
      "63: SPDIF Interface (Realtek USB Audio)\n",
      "64: Headset Earphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "65: Headset Microphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "66: Microphone (Steam Streaming Microphone Wave)\n",
      "67: Speakers (Steam Streaming Microphone Wave)\n",
      "68: Input (Steam Streaming Speakers Wave)\n",
      "69: Speakers (Steam Streaming Speakers Wave)\n",
      "70: Headset Earphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(small bro))\n",
      "71: Headset Microphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(small bro))\n",
      "72: Speakers ()\n",
      "73: Speakers ()\n",
      "Listening...\n",
      "You said: find me the file test doc\n",
      "Response from interact with Ollama: search\n",
      "Intent: search\n",
      "e:/Adv perception\\Assignment-1-Adv-Perceptron-\\__pycache__\\test.cpython-39.pyc\n",
      "e:/Masters\\FAI project\\PPO test.png\n",
      "e:/Masters\\FAI project\\MarioRL-main\\Mario Test DQN.ipynb\n",
      "Listening...\n",
      "You said: open the first one\n",
      "Response from interact with Ollama: read\n",
      "Intent: read\n",
      "Response from interact with Ollama: first.one\n",
      "Document name: first.one\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\process.py:108\u001b[0m, in \u001b[0;36mextractWithoutOrder\u001b[1;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# See if choices is a dictionary-like object.\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, choice \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchoices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[0;32m    109\u001b[0m         processed \u001b[38;5;241m=\u001b[39m pre_processor(processor(choice))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 258\u001b[0m\n\u001b[0;32m    255\u001b[0m             speak(result)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 258\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 252\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    249\u001b[0m     speak(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoodbye!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmic_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "Cell \u001b[1;32mIn[6], line 208\u001b[0m, in \u001b[0;36mexecute_command\u001b[1;34m(command, mic_index, file_df)\u001b[0m\n\u001b[0;32m    205\u001b[0m document_name \u001b[38;5;241m=\u001b[39m interact_with_ollama(command)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, document_name)\n\u001b[1;32m--> 208\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m \u001b[43msearch_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile_df\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Search for the document in the indexed files\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile paths from db search:\u001b[39m\u001b[38;5;124m\"\u001b[39m, file_paths)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# If multiple files are found, ask the user to specify the file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 162\u001b[0m, in \u001b[0;36msearch_files\u001b[1;34m(file_name, file_df)\u001b[0m\n\u001b[0;32m    159\u001b[0m file_names \u001b[38;5;241m=\u001b[39m file_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Convert file names to a list\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Use fuzzy matching to find the closest file names\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m matched_files \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matched_files:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# Retrieve the file path based on the matched file name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\process.py:168\u001b[0m, in \u001b[0;36mextract\u001b[1;34m(query, choices, processor, scorer, limit)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Select the best match in a list or dictionary of choices.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mFind best matches in a list or dictionary of choices, return a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    [('train', 22, 'bard'), ('man', 0, 'dog')]\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m sl \u001b[38;5;241m=\u001b[39m extractWithoutOrder(query, choices, processor, scorer)\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mheapq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28msorted\u001b[39m(sl, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m i: i[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\heapq.py:570\u001b[0m, in \u001b[0;36mnlargest\u001b[1;34m(n, iterable, key)\u001b[0m\n\u001b[0;32m    568\u001b[0m order \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mn\n\u001b[0;32m    569\u001b[0m _heapreplace \u001b[38;5;241m=\u001b[39m heapreplace\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    571\u001b[0m     k \u001b[38;5;241m=\u001b[39m key(elem)\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m top \u001b[38;5;241m<\u001b[39m k:\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\process.py:117\u001b[0m, in \u001b[0;36mextractWithoutOrder\u001b[1;34m(query, choices, processor, scorer, score_cutoff)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices:\n\u001b[0;32m    116\u001b[0m     processed \u001b[38;5;241m=\u001b[39m pre_processor(processor(choice))\n\u001b[1;32m--> 117\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m score_cutoff:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (choice, score)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:297\u001b[0m, in \u001b[0;36mWRatio\u001b[1;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     tsor \u001b[38;5;241m=\u001b[39m token_sort_ratio(p1, p2, full_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m*\u001b[39m unbase_scale\n\u001b[1;32m--> 297\u001b[0m     tser \u001b[38;5;241m=\u001b[39m \u001b[43mtoken_set_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m unbase_scale\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mintr(\u001b[38;5;28mmax\u001b[39m(base, tsor, tser))\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:169\u001b[0m, in \u001b[0;36mtoken_set_ratio\u001b[1;34m(s1, s2, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoken_set_ratio\u001b[39m(s1, s2, force_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, full_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_token_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:163\u001b[0m, in \u001b[0;36m_token_set\u001b[1;34m(s1, s2, partial, force_ascii, full_process)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     ratio_func \u001b[38;5;241m=\u001b[39m ratio\n\u001b[0;32m    160\u001b[0m pairwise \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    161\u001b[0m     ratio_func(sorted_sect, combined_1to2),\n\u001b[0;32m    162\u001b[0m     ratio_func(sorted_sect, combined_2to1),\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mratio_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_1to2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined_2to1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m ]\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(pairwise)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\utils.py:38\u001b[0m, in \u001b[0;36mcheck_for_none.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\utils.py:29\u001b[0m, in \u001b[0;36mcheck_for_equivalence.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m args[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\utils.py:47\u001b[0m, in \u001b[0;36mcheck_empty_string.<locals>.decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:27\u001b[0m, in \u001b[0;36mratio\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_none\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_for_equivalence\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_empty_string\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(s1, s2):\n\u001b[0;32m     25\u001b[0m     s1, s2 \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmake_type_consistent(s1, s2)\n\u001b[1;32m---> 27\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mintr(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m m\u001b[38;5;241m.\u001b[39mratio())\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\difflib.py:182\u001b[0m, in \u001b[0;36mSequenceMatcher.__init__\u001b[1;34m(self, isjunk, a, b, autojunk)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautojunk \u001b[38;5;241m=\u001b[39m autojunk\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\difflib.py:194\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seqs\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set the two sequences to be compared.\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m>>> s = SequenceMatcher()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m0.75\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_seq1(a)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seq2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\difflib.py:248\u001b[0m, in \u001b[0;36mSequenceMatcher.set_seq2\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatching_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopcodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullbcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__chain_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aniru\\anaconda3\\envs\\AIHCI\\lib\\difflib.py:282\u001b[0m, in \u001b[0;36mSequenceMatcher.__chain_b\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, elt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(b):\n\u001b[0;32m    281\u001b[0m     indices \u001b[38;5;241m=\u001b[39m b2j\u001b[38;5;241m.\u001b[39msetdefault(elt, [])\n\u001b[1;32m--> 282\u001b[0m     \u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Purge junk elements\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbjunk \u001b[38;5;241m=\u001b[39m junk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Database Initialization and File Indexing\n",
    "# class FileIndexer:\n",
    "#     def __init__(self, db_name=\"file_index.db\"):\n",
    "#         self.db_name = db_name\n",
    "#         self.initialize_database()\n",
    "#         self.index_files()\n",
    "\n",
    "#     def initialize_database(self):\n",
    "#         \"\"\"Creates a database to index system files.\"\"\"\n",
    "#         conn = sqlite3.connect(self.db_name)\n",
    "#         cursor = conn.cursor()\n",
    "#         cursor.execute('''CREATE TABLE IF NOT EXISTS files (id INTEGER PRIMARY KEY, name TEXT, path TEXT)''')\n",
    "#         conn.commit()\n",
    "#         conn.close()\n",
    "\n",
    "#     def index_files(self):\n",
    "#         \"\"\"Indexes all files in the system.\"\"\"\n",
    "#         conn = sqlite3.connect(self.db_name)\n",
    "#         cursor = conn.cursor()\n",
    "#         for root, dirs, files in os.walk(\"E:/AIHCI-Blind/test\"):  # Change path as needed\n",
    "#             for file in files:\n",
    "#                 print(file)\n",
    "#                 cursor.execute(\"INSERT INTO files (name, path) VALUES (?, ?)\", (file, os.path.join(root, file)))\n",
    "#         conn.commit()\n",
    "#         conn.close()\n",
    "\n",
    "# Microphone Handling\n",
    "class MicrophoneHandler:\n",
    "    def list_microphones(self):\n",
    "        \"\"\"Lists all available microphones.\"\"\"\n",
    "        mic_list = sr.Microphone.list_microphone_names()\n",
    "        print(\"Available microphones:\")\n",
    "        for i, microphone_name in enumerate(mic_list):\n",
    "            print(f\"{i}: {microphone_name}\")\n",
    "        return mic_list\n",
    "\n",
    "    def select_microphone(self):\n",
    "        \"\"\"Prompts the user to select a microphone by index.\"\"\"\n",
    "        mic_list = self.list_microphones()\n",
    "        try:\n",
    "            mic_index = int(input(\"Enter the microphone index you want to use: \"))\n",
    "            if mic_index >= 0 and mic_index < len(mic_list):\n",
    "                return mic_index\n",
    "            else:\n",
    "                print(\"Invalid index, using the default microphone.\")\n",
    "                return None\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, using the default microphone.\")\n",
    "            return None\n",
    "\n",
    "# Speech Handling Functions\n",
    "def speak(text):\n",
    "    \"\"\"Converts text to speech.\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def listen(mic_index=None):\n",
    "    \"\"\"Listens to the user's voice input using the selected microphone.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index) if mic_index is not None else sr.Microphone()\n",
    "    with mic as source:\n",
    "        print(\"Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {command}\")\n",
    "            return command.lower()\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I didn't catch that.\")\n",
    "        except sr.RequestError:\n",
    "            speak(\"Sorry, there was a network error.\")\n",
    "    return \"\"\n",
    "\n",
    "# LLM Interface\n",
    "def interact_with_ollama(prompt):\n",
    "    \"\"\"Sends the user prompt to Ollama and receives a CLI command.\"\"\"\n",
    "    try:\n",
    "        stream = ollama.chat(\n",
    "            model='llama3.1:8b',\n",
    "            messages=[{'role': 'user', 'content': prompt}],\n",
    "            stream=True\n",
    "        )\n",
    "        response = \"\"\n",
    "        for chunk in stream:\n",
    "            response += chunk['message']['content']\n",
    "        print(\"Response from interact with Ollama:\", response.strip())\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Sorry, something went wrong.\"\n",
    "    \n",
    "\n",
    "# Intent Classification\n",
    "def get_intent(command):\n",
    "    \"\"\"Determines intent of user command.\"\"\"\n",
    "    prompt = f\"Classify this command as one of the following: 'changedirectory', 'list', 'read' or 'search'. Reply with only one word from this list, without any extra text, punctuation, or phrases, based on the command given after the colon:'{command}'\"\n",
    "    # print the intent\n",
    "    response = interact_with_ollama(prompt)\n",
    "\n",
    "    return response.strip().lower()\n",
    "\n",
    "# Command Execution Functions\n",
    "def change_directory(command):\n",
    "    \"\"\"Executes a 'change directory' command.\"\"\"\n",
    "    directory = interact_with_ollama(command)\n",
    "    print(\"Directory to change to:\", directory)\n",
    "    try:\n",
    "        os.chdir(directory)\n",
    "        current_dir = os.getcwd()\n",
    "        # Open the same directory in Windows Explorer\n",
    "        subprocess.Popen(f'explorer \"{current_dir}\"')\n",
    "        speak(f\"Changed directory to {current_dir}\")\n",
    "        return current_dir\n",
    "    except Exception as e:\n",
    "        speak(f\"Error changing directory: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def list_files():\n",
    "    \"\"\"Lists files in the current directory.\"\"\"\n",
    "    try:\n",
    "        files = os.listdir()\n",
    "        result = \"\\n\".join(files) if files else \"No files found in this directory.\"\n",
    "        speak(f\"Files in current directory are: {result}\")\n",
    "        return result\n",
    "    except PermissionError:\n",
    "        speak(\"Permission denied. Unable to list the contents of this directory.\")\n",
    "        return \"Error: Permission denied.\"\n",
    "\n",
    "# def search_files(query):\n",
    "#     \"\"\"Searches indexed files using a query.\"\"\"\n",
    "#     conn = sqlite3.connect(\"file_index.db\")\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name, path FROM files\")\n",
    "#     files = cursor.fetchall()\n",
    "#     conn.close()\n",
    "\n",
    "#     search_term = \" \".join(query.split()[1:])\n",
    "#     matched_files = process.extract(search_term, [file[0] for file in files], limit=5)\n",
    "#     results = []\n",
    "\n",
    "#     for match in matched_files:\n",
    "#         file_name, path = next((f for f in files if f[0] == match[0]), (None, None))\n",
    "#         if path:\n",
    "#             results.append(f\"{file_name} located at {path}\")\n",
    "#             speak(f\"{file_name} located at {path}\")\n",
    "\n",
    "#     return \"\\n\".join(results) if results else \"No matching files found.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_files(file_name,file_df):\n",
    "    \"\"\"Searches indexed files using a query with the DataFrame.\"\"\"\n",
    "    #search_term = \" \".join(query.split()[1:])  # Extract the search term from the query\n",
    "    file_names = file_df['File name'].tolist()  # Convert file names to a list\n",
    "\n",
    "    # Use fuzzy matching to find the closest file names\n",
    "    matched_files = process.extract(file_name, file_names, limit=3)\n",
    "    results = []\n",
    "\n",
    "    for match in matched_files:\n",
    "        # Retrieve the file path based on the matched file name\n",
    "        file_row = file_df[file_df['File name'] == match[0]]\n",
    "        if not file_row.empty:\n",
    "            file_path = file_row.iloc[0]['Path']  # Get the first matched path\n",
    "            results.append(file_path)\n",
    "            speak(f\"{match[0]} located at {file_path}\")\n",
    "\n",
    "    return \"\\n\".join(results) if results else \"No matching files found.\"\n",
    "\n",
    "# Command Routing\n",
    "def execute_command(command,mic_index,file_df):\n",
    "    \"\"\"Routes the command based on intent.\"\"\"\n",
    "    intent = get_intent(command)\n",
    "    print(\"Intent:\", intent)\n",
    "    if intent == \"changedirectory\":\n",
    "        print(\"I am in the change directory intent\")\n",
    "        # chance directory prompt for llama to take into account we are using os.chdir(\"\") and want what we want to put in the brackets\n",
    "        command = f\"Translate the following request into only the directory path needed for os.chdir, without any extra words, explanations, or punctuation: '{command}'\"\n",
    "        return change_directory(command)\n",
    "    elif intent == \"list\":\n",
    "        # list files prompt for llama to take into account we are using os.listdir() and want what we want to put in the brackets\n",
    "        command = f\"Translate the following request into a command suitable for os.listdir(): '{command}'\"\n",
    "        return list_files()\n",
    "    elif intent == \"search\":\n",
    "        # search files prompt for llama to take into account we are using the search function and want what we want to put in the brackets\n",
    "        command = f\"Translate the following request into a search query: '{command}'\"\n",
    "        return search_files(command,file_df)\n",
    "    elif intent == \"read\":\n",
    "        \n",
    "        # Get the current working directory\n",
    "        current_directory = os.getcwd()\n",
    "\n",
    "        # Extract the drive letter\n",
    "        current_drive = os.path.splitdrive(current_directory)[0]\n",
    "        \n",
    "        # Handle document reading command\n",
    "        #document_name = command.split(\"read\")[-1].strip()  # Extract document name from command\n",
    "\n",
    "        command =f\"Extract only the file name from the following command without any extra text, words, or punctuation and if there is dot in the command change it it '.': '{command}'\"\n",
    "        document_name = interact_with_ollama(command)\n",
    "\n",
    "        print(\"Document name:\", document_name)\n",
    "        file_paths = search_files(document_name,file_df)  # Search for the document in the indexed files\n",
    "        print(\"File paths from db search:\", file_paths)\n",
    "\n",
    "        # If multiple files are found, ask the user to specify the file\n",
    "        if len(file_paths.split(\"\\n\")) > 0:\n",
    "            speak(\"Multiple files found. Please specify the file you want to read.\")\n",
    "            filenumber = listen(mic_index)\n",
    "            # pass the list to llama to get the file path based on our input number/ choice\n",
    "            command = f\"Translate the following request into a file path corresponding to the file number in the list of gile given you want to read from {file_paths} only return the corrsponding file pathwithout any extra text, words, or punctuation : '{filenumber}'\"\n",
    "            file_path = interact_with_ollama(command)\n",
    "\n",
    "            print(\"File path from llama:\", file_path)\n",
    "            \n",
    "            #file_path = search_files(file_name,file_df)\n",
    "\n",
    "        \n",
    "        #file_path=r\"E:\\AIHCI-Blind\\test\\test.docx\"\n",
    "\n",
    "        print(\"File path:\", file_path)\n",
    "        \n",
    "        if file_path:\n",
    "            return edit_document(mic_index,file_path)  # Call the document reader function\n",
    "        else:\n",
    "            speak(\"Document not found.\")\n",
    "            return \"Document not found.\"\n",
    "    else:\n",
    "        speak(\"Sorry, I can only execute 'cd', 'ls', or 'search' commands.\")\n",
    "        return \"Invalid command\"\n",
    "\n",
    "# Main Pipeline\n",
    "def main():\n",
    "    #indexer = FileIndexer()\\\n",
    "    file_df = pd.read_pickle(\"file_list.pkl\")\n",
    "    mic_handler = MicrophoneHandler()\n",
    "    mic_index = mic_handler.select_microphone()  # Select microphone\n",
    "\n",
    "    speak(\"Hello! I am ready to assist you with basic command line tasks. Please tell me what you want to do.\")\n",
    "    \n",
    "    while True:\n",
    "        user_command = listen(mic_index)\n",
    "        if \"exit\" in user_command:\n",
    "            speak(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        result = execute_command(user_command,mic_index,file_df)\n",
    "        print(result)\n",
    "        if result:\n",
    "            speak(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIHCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
