{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from docx import Document\n",
    "import ollama\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TTS engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "# Function to speak text\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available microphones\n",
    "def list_microphones():\n",
    "    mic_list = sr.Microphone.list_microphone_names()\n",
    "    print(\"Available microphones:\")\n",
    "    for i, microphone_name in enumerate(mic_list):\n",
    "        print(f\"{i}: {microphone_name}\")\n",
    "    return mic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select microphone\n",
    "def select_microphone():\n",
    "    mic_list = list_microphones()\n",
    "    try:\n",
    "        mic_index = int(input(\"Enter the microphone index you want to use: \"))\n",
    "        if mic_index >= 0 and mic_index < len(mic_list):\n",
    "            return mic_index\n",
    "        else:\n",
    "            print(\"Invalid index, using the default microphone.\")\n",
    "            return None\n",
    "    except ValueError:\n",
    "        print(\"Invalid input, using the default microphone.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to voice commands\n",
    "def listen(mic_index=None):\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone(device_index=mic_index) if mic_index is not None else sr.Microphone()\n",
    "    \n",
    "    with mic as source:\n",
    "        print(\"Listening for command...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "        \n",
    "        try:\n",
    "            command = recognizer.recognize_google(audio)\n",
    "            print(f\"You said: {command}\")\n",
    "            return command.lower()\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I didn't catch that.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError:\n",
    "            speak(\"Sorry, there was a network error.\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent recognition using LLM\n",
    "def recognize_intent_with_llm(command):\n",
    "    prompt = (\n",
    "        f\"Classify this command as one of the following::'add_text', 'delete_line', 'read_document', 'read_line', 'next_line', 'previous_line', 'edit_line', 'read_between_lines' , 'summarize' , 'exit'.Reply with only one word from this list, without any extra text, punctuation, or phrases, based on the command given after the colon:'{command}\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    intent = \"\"\n",
    "    for chunk in stream:\n",
    "        intent += chunk['message']['content']\n",
    "    print(f\"Intent: {intent.strip().lower()}\")\n",
    "    return intent.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_range_with_llm(command):  \n",
    "\n",
    "    prompt = (\n",
    "        f\"User input: \\\"{command}\\\"\\n\"\n",
    "        \"Extract and return two numbers separated by a comma from the input, specifying line numbers or a range.- If a range is mentioned (e.g., 'lines 3 to 5' or 'read lines 2 through 4'), return the start and end numbers (e.g., '3,5' or '2,4').- If a single line is mentioned (e.g., 'line 7' or 'read line 10'), return the same number twice (e.g., '7,7' or '10,10').Provide only the two numbers separated by a comma and nothing else.\"\n",
    "        #\"- For inputs that don't mention any line numbers, return '0,0'.\\n\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    line_range = \"\"\n",
    "    for chunk in stream:\n",
    "        line_range += chunk['message']['content']\n",
    "    \n",
    "    # Parse the LLM response\n",
    "    line_range = line_range.strip()\n",
    "    print(f\"Line range: {line_range}\")\n",
    "    try:\n",
    "        start_line, end_line = map(int, line_range.split(','))\n",
    "    except ValueError:\n",
    "        return None, None  # Return None if parsing fails\n",
    "    \n",
    "    return start_line, end_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_or_paragraph_range_with_llm(command):\n",
    "    prompt = (\n",
    "        f\"User input: \\\"{command}\\\"\\n\"\n",
    "        \"Determine whether the input refers to lines or paragraphs, and extract the numeric range.\\n\"\n",
    "        \"Respond with one of the following formats:\\n\"\n",
    "        \"- If the input specifies a range of lines (e.g., 'read lines 3 to 5'), respond with 'line:3,5'.\\n\"\n",
    "        \"- If the input specifies a single line (e.g., 'read line 7'), respond with 'line:7,7'.\\n\"\n",
    "        \"- If the input specifies a range of paragraphs (e.g., 'read paragraphs 2 to 4'), respond with 'paragraph:2,4'.\\n\"\n",
    "        \"- If the input specifies a single paragraph (e.g., 'paragraph 3'), respond with 'paragraph:3,3'.\\n\"\n",
    "        \"Provide only the specified output format and nothing else.\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk['message']['content']\n",
    "    \n",
    "    # Parse the LLM response\n",
    "    response = response.strip()\n",
    "    print(f\"LLM Response: {response}\")\n",
    "    \n",
    "    try:\n",
    "        mode, range_values = response.split(\":\")\n",
    "        start, end = map(int, range_values.split(','))\n",
    "    except ValueError:\n",
    "        return None, None, None  # Return None if parsing fails\n",
    "    \n",
    "    if mode not in ['line', 'paragraph']:\n",
    "        return None, None, None  # Ensure mode is either 'line' or 'paragraph'\n",
    "    \n",
    "    return start, end, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and initialize document\n",
    "def open_document(filename):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        return Document(filename)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        with open(filename, \"r+\") as file:\n",
    "            return file.read().splitlines()  # Treat each line as an entry in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save changes to the document\n",
    "def save_document(content, filename):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        content.save(filename)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(\"\\n\".join(content))  # Save content list back to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text to the document\n",
    "def add_text(content, filename, new_text):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        content.add_paragraph(new_text)\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        content.append(new_text)\n",
    "    speak(\"Text added successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete text by line number\n",
    "def delete_line(content, line_num, filename):\n",
    "    try:\n",
    "        if filename.endswith(\".docx\"):\n",
    "            paragraph = content.paragraphs[line_num]\n",
    "            paragraph.clear()\n",
    "        elif filename.endswith(\".txt\"):\n",
    "            content.pop(line_num)\n",
    "        speak(\"Line deleted successfully.\")\n",
    "    except IndexError:\n",
    "        speak(\"Invalid line number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LLM to edit a specific line\n",
    "def edit_line_with_llm(original_line, edit_instruction):\n",
    "    prompt = (\n",
    "        f\"Original line: \\\"{original_line}\\\"\\n\"\n",
    "        f\"Edit request: {edit_instruction}\\n\"\n",
    "        \"Provide only the updated line with no extra text:\"\n",
    "    )\n",
    "    # Send prompt to LLM\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.1:8b',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    edited_line = \"\"\n",
    "    for chunk in stream:\n",
    "        edited_line += chunk['message']['content']\n",
    "\n",
    "    return edited_line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_document(content, filename, line_start=None, line_end=None):\n",
    "    if filename.endswith(\".docx\"):\n",
    "        # Extract paragraphs as a list of lines\n",
    "        lines = [p.text for p in content.paragraphs]\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        # Treat content as a list of lines\n",
    "        lines = content\n",
    "    \n",
    "    # Adjust for single-line reading if no range provided\n",
    "    if line_start is not None and line_end is None:\n",
    "        text_to_read = lines[line_start - 1]  # 1-based index\n",
    "    elif line_start is not None and line_end is not None:\n",
    "        text_to_read = \"\\n\".join(lines[line_start - 1:line_end])  # 1-based inclusive range\n",
    "    else:\n",
    "        text_to_read = \"\\n\".join(lines)  # Default to full document\n",
    "\n",
    "    speak(text_to_read)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def summarize_range(content, filename, start, end, paragraph_flag='line'):\n",
    "    \n",
    "    if paragraph_flag == None:\n",
    "        paragraph_flag = 'line'\n",
    "    \n",
    "    # Determine lines or paragraphs based on file type and mode\n",
    "    if filename.endswith(\".docx\"):\n",
    "        if paragraph_flag == 'paragraph':\n",
    "            # Extract paragraphs\n",
    "            items = [p.text for p in content.paragraphs if p.text.strip()]\n",
    "        else:\n",
    "            # Extract lines by splitting paragraphs\n",
    "            items = [line for p in content.paragraphs for line in p.text.split(\"\\n\")]\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        if paragraph_flag == 'paragraph':\n",
    "            # Split content into paragraphs\n",
    "            items = content.split(\"\\n\\n\")\n",
    "        else:\n",
    "            # Split content into lines\n",
    "            items = content.split(\"\\n\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .docx or .txt file.\")\n",
    "\n",
    "    # Validate range\n",
    "    if start < 1 or end > len(items):\n",
    "        return \"Invalid range specified.\"\n",
    "\n",
    "    # Extract the relevant range\n",
    "    selected_text = \"\\n\".join(items[start - 1:end])  \n",
    "    print(f\"Selected text:\\n{selected_text}\")\n",
    "\n",
    "    # Use the Llama model to summarize the selected text\n",
    "    prompt = f\"Summarize the following text:\\n\\n{selected_text}\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3.1:8b',\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        summary = \"\".join(chunk['message']['content'] for chunk in response)\n",
    "        return summary.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in summarizing: {e}\")\n",
    "        return f\"Error in summarizing: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main editing function\n",
    "def main():\n",
    "    # Select microphone\n",
    "    mic_index = select_microphone()\n",
    "    \n",
    "    # Hardcoded file path for testing\n",
    "    filename = r\"E:\\BlindSight\\test\\test.docx\"  # Replace with your test file path\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        speak(\"File not found. Please try again.\")\n",
    "        return\n",
    "\n",
    "    # Open the document\n",
    "    content = open_document(filename)\n",
    "    current_line = 0\n",
    "\n",
    "    speak(\"File opened successfully. You can say commands like add text, delete line, edit line, or read document.\")\n",
    "    \n",
    "    while True:\n",
    "        command = listen(mic_index)\n",
    "        intent = recognize_intent_with_llm(command)\n",
    "        \n",
    "        if intent == \"exit\":\n",
    "            save_document(content, filename)\n",
    "            speak(\"Changes saved. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        elif intent == \"add_text\":\n",
    "            speak(\"What text would you like to add?\")\n",
    "            new_text = listen(mic_index)\n",
    "            add_text(content, filename, new_text)\n",
    "\n",
    "        elif intent == \"delete_line\":\n",
    "            speak(\"Which line number would you like to delete?\")\n",
    "            try:\n",
    "                #line_num = int(listen(mic_index))\n",
    "                # TODO: add the line number detection here\n",
    "                line_num, _ , _= get_line_or_paragraph_range_with_llm(command)\n",
    "                delete_line(content, line_num - 1, filename)\n",
    "            except ValueError:\n",
    "                speak(\"Invalid line number.\")\n",
    "\n",
    "        elif intent == \"read_document\":\n",
    "            read_document(content, filename)\n",
    "\n",
    "        elif intent == \"read_line\":\n",
    "            #speak(\"Which line number would you like to hear?\")\n",
    "            try:\n",
    "                #line_num = int(listen(mic_index))\n",
    "                #read_document(content, filename, line_num - 1)\n",
    "\n",
    "                #line_command = listen(mic_index)\n",
    "    \n",
    "                # Use LLM to extract the line number from the user's command\n",
    "                line_num, _ , _= get_line_or_paragraph_range_with_llm(command)\n",
    "                print(line_num)\n",
    "                read_document(content, filename, line_start=line_num)\n",
    "            except ValueError:\n",
    "                speak(\"Invalid line number.\")\n",
    "        \n",
    "        elif intent == \"next_line\":\n",
    "            current_line += 1\n",
    "            read_document(content, filename, line_start=current_line)\n",
    "\n",
    "        elif intent == \"previous_line\":\n",
    "            current_line = max(0, current_line - 1)\n",
    "            read_document(content, filename, line_start=current_line)\n",
    "        \n",
    "        elif intent == \"edit_line\":\n",
    "            #speak(\"Which line number would you like to edit?\")\n",
    "            try:\n",
    "                line_command = listen(mic_index)\n",
    "    \n",
    "                # Use LLM to extract the line number from the user's command\n",
    "                line_num, _ , _= get_line_or_paragraph_range_with_llm(command)\n",
    "                \n",
    "                \n",
    "                #line_num = line_num - 1\n",
    "                original_line = content.paragraphs[line_num].text if filename.endswith(\".docx\") else content[line_num]\n",
    "                \n",
    "                speak(\"What changes would you like to make?\")\n",
    "                edit_instruction = listen(mic_index)\n",
    "                \n",
    "                # Get edited line from LLM\n",
    "                edited_line = edit_line_with_llm(original_line, edit_instruction)\n",
    "                \n",
    "                # Update the document with the edited line\n",
    "                if filename.endswith(\".docx\"):\n",
    "                    content.paragraphs[line_num].text = edited_line\n",
    "                elif filename.endswith(\".txt\"):\n",
    "                    content[line_num] = edited_line\n",
    "                \n",
    "                speak(\"Line edited successfully.\")\n",
    "            except (ValueError, IndexError):\n",
    "                speak(\"Invalid line number or edit command.\")\n",
    "        elif intent == \"summarize\":\n",
    "            #ask which paragraph to summarize\n",
    "            start , end , para = get_line_or_paragraph_range_with_llm(command)\n",
    "            summary = summarize_range(content, filename , start, end, paragraph_flag=para )\n",
    "            speak(summary)\n",
    "        elif intent == \"read_between_lines\":\n",
    "            #ask for the two lines\n",
    "            try:\n",
    "                start_line_num, end_line_num , paragraph = get_line_or_paragraph_range_with_llm(command)\n",
    "                print(\"i am in read between lines\")\n",
    "                print(start_line_num,end_line_num)\n",
    "                read_document(content, filename, line_start=start_line_num, line_end=end_line_num)\n",
    "            except ValueError:\n",
    "                speak(\"Invalid line numbers.\")\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            speak(\"Sorry, I didn't understand that command. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available microphones:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Microphone (3- USB PnP Audio De\n",
      "2: Microphone (G435 Wireless Gamin\n",
      "3: Headset Microphone (Oculus Virt\n",
      "4: Microphone (Realtek USB Audio)\n",
      "5: Microphone (Steam Streaming Mic\n",
      "6: Microsoft Sound Mapper - Output\n",
      "7: Headset Earphone (G435 Wireless\n",
      "8: Headphones (Realtek USB Audio)\n",
      "9: ASUS VG32V (NVIDIA High Definit\n",
      "10: Headphones (Oculus Virtual Audi\n",
      "11: Realtek Digital Output (Realtek\n",
      "12: Speakers (Steam Streaming Speak\n",
      "13: Speakers (Steam Streaming Micro\n",
      "14: U32J59x (NVIDIA High Definition\n",
      "15: Primary Sound Capture Driver\n",
      "16: Microphone (3- USB PnP Audio Device)\n",
      "17: Microphone (G435 Wireless Gaming Headset)\n",
      "18: Headset Microphone (Oculus Virtual Audio Device)\n",
      "19: Microphone (Realtek USB Audio)\n",
      "20: Microphone (Steam Streaming Microphone)\n",
      "21: Primary Sound Driver\n",
      "22: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "23: Headphones (Realtek USB Audio)\n",
      "24: ASUS VG32V (NVIDIA High Definition Audio)\n",
      "25: Headphones (Oculus Virtual Audio Device)\n",
      "26: Realtek Digital Output (Realtek USB Audio)\n",
      "27: Speakers (Steam Streaming Speakers)\n",
      "28: Speakers (Steam Streaming Microphone)\n",
      "29: U32J59x (NVIDIA High Definition Audio)\n",
      "30: Headphones (Realtek USB Audio)\n",
      "31: ASUS VG32V (NVIDIA High Definition Audio)\n",
      "32: Headphones (Oculus Virtual Audio Device)\n",
      "33: Realtek Digital Output (Realtek USB Audio)\n",
      "34: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "35: Speakers (Steam Streaming Speakers)\n",
      "36: Speakers (Steam Streaming Microphone)\n",
      "37: U32J59x (NVIDIA High Definition Audio)\n",
      "38: Microphone (G435 Wireless Gaming Headset)\n",
      "39: Headset Microphone (Oculus Virtual Audio Device)\n",
      "40: Microphone (Realtek USB Audio)\n",
      "41: Microphone (3- USB PnP Audio Device)\n",
      "42: Microphone (Steam Streaming Microphone)\n",
      "43: Microphone (USB PnP Audio Device)\n",
      "44: Output 1 (OCULUSVAD Wave Speaker Headphone)\n",
      "45: Output 2 (OCULUSVAD Wave Speaker Headphone)\n",
      "46: Input (OCULUSVAD Wave Speaker Headphone)\n",
      "47: Headset Microphone (OCULUSVAD Wave Microphone Headphone)\n",
      "48: Microphone (G435 Wireless Gaming Headset)\n",
      "49: Headset Earphone (G435 Wireless Gaming Headset)\n",
      "50: Output (NVIDIA High Definition Audio)\n",
      "51: Output ()\n",
      "52: Line In (Realtek USB Audio)\n",
      "53: Microphone (Realtek USB Audio)\n",
      "54: Stereo Mix (Realtek USB Audio)\n",
      "55: Headphones (Realtek USB Audio)\n",
      "56: Speakers (Realtek USB Audio)\n",
      "57: SPDIF Interface (Realtek USB Audio)\n",
      "58: Headset Earphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "59: Headset Microphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(Big bro))\n",
      "60: Microphone (Steam Streaming Microphone Wave)\n",
      "61: Speakers (Steam Streaming Microphone Wave)\n",
      "62: Input (Steam Streaming Speakers Wave)\n",
      "63: Speakers (Steam Streaming Speakers Wave)\n",
      "64: Headset Earphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(small bro))\n",
      "65: Headset Microphone (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free%0\n",
      ";(small bro))\n",
      "66: Speakers ()\n",
      "67: Speakers ()\n",
      "Listening for command...\n",
      "You said: summarize second paragraph\n",
      "Intent: summarize\n",
      "LLM Response: line:1,2\n",
      "Error in summarizing: string indices must be integers\n",
      "Listening for command...\n",
      "Intent: i'm ready to classify. what's the command?\n",
      "Listening for command...\n",
      "You said: goodbye\n",
      "Intent: exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIHCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
